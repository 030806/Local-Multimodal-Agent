from sentence_transformers import SentenceTransformer, util
from modules.config import EMBEDDING_MODEL_PATH
import torch
import re
# import nltk
# try:
#     nltk.data.find('tokenizers/punkt_tab')
# except LookupError:
#     print("ğŸ“¥ æ­£åœ¨ä¸‹è½½ç¼ºå¤±çš„ nltk èµ„æº: punkt_tab...")
#     nltk.download('punkt_tab')
# ----------------------

class SemanticClassifier:
    def __init__(self):
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½åˆ†ç±»æ¨¡å‹: {EMBEDDING_MODEL_PATH} ...")
        self.model = SentenceTransformer(EMBEDDING_MODEL_PATH)

    def _clean_text(self, text):
        """
        æ¿€è¿›æ¸…æ´—ï¼šåªä¿ç•™æœ€èƒ½ä½“ç°å­¦ç§‘ç‰¹å¾çš„è¯æ±‡ã€‚
        """
        # 1. ç»Ÿä¸€è½¬å°å†™
        text = text.lower()

        # 2. å°è¯•å®šä½ Abstract å…³é”®è¯ï¼Œå› ä¸ºæ‘˜è¦æœ€æœ‰ä»£è¡¨æ€§
        abstract_pos = text.find("abstract")
        if abstract_pos != -1:
            # å–æ‘˜è¦å¼€å§‹åçš„ 1200 ä¸ªå­—ç¬¦
            text = text[abstract_pos:abstract_pos + 1200]
        else:
            # å¦‚æœæ²¡æ‰¾åˆ° Abstractï¼Œå–å‰ 1500 ä¸ªå­—ç¬¦ï¼ˆé¿å¼€æœ€é¡¶éƒ¨çš„ä½œè€…å­¦æ ¡ä¿¡æ¯ï¼‰
            text = text[200:1500]

        # 3. ç§»é™¤å¹²æ‰°é¡¹ï¼šç§»é™¤å¸¸è§çš„å­¦æ ¡åç§°ã€é‚®ç®±åç¼€ã€æ—¥æœŸç­‰å™ªéŸ³
        text = re.sub(r'\S+@\S+', '', text)  # ç§»é™¤é‚®ç®±
        text = re.sub(r'http\S+', '', text)  # ç§»é™¤é“¾æ¥

        return text

    def classify_paper(self, text_content, topics):
        # 1. æ–‡æœ¬æ¸…æ´—ï¼šåªå–æ‘˜è¦éƒ¨åˆ†ï¼Œå‡å°‘å™ªéŸ³
        input_text = self._clean_text(text_content)

        # 2. è¯­ä¹‰å¢å¼ºç­–ç•¥ï¼šä¸ºæ¯ä¸ªä¸»é¢˜å®šä¹‰â€œç‰¹å¾è¯ç¾¤â€
        topic_enhancement = {
            "NLP": "natural language processing, Natural Language Processing, NLP, text sequences, translation, "
                   "vocabulary, linguistics, transformer, bert, word embedding,language model,llm,text generation,"
                   "machine translation,question answering,dialogue,information extraction,sentiment",
            "Computer Vision": "Computer Vision, CV, image recognition, object detection, pixel, convolutional neural networks, CNN, ResNet, vision, video,3d vision,anomaly detection,image segmentation,image classification",
            "Reinforcement Learning": "Reinforcement Learning, RL, agent, reward, policy gradient, MDP, environment, Q-learning, action space,game theory",
            "Deep Learning":"neural network,cnn,rnn,lstm,transformer,attention,gan,diffusion,autoencoder,gnn,graph neural",

        }

        # æ„å»ºå¯¹æ¯”å‘é‡ï¼šä¼˜å…ˆä½¿ç”¨å¢å¼ºè¯ç¾¤ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”¨åŸè¯
        enhanced_topics = [topic_enhancement.get(t, t) for t in topics]

        # 3. è®¡ç®—å‘é‡
        text_embedding = self.model.encode(input_text, convert_to_tensor=True)
        topic_embeddings = self.model.encode(enhanced_topics, convert_to_tensor=True)

        # 4. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        cosine_scores = util.cos_sim(text_embedding, topic_embeddings)[0]

        # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼Œçœ‹æ¯ä¸ªä¸»é¢˜çš„å¾—åˆ†
        for i, t in enumerate(topics):
            print(f"DEBUG: ä¸»é¢˜ [{t}] å¾—åˆ†: {cosine_scores[i].item():.4f}")

        best_score_idx = torch.argmax(cosine_scores).item()
        return topics[best_score_idx]