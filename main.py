import argparse
import os
import shutil
from modules.vector_store import VectorDBManager
from modules.classifier import SemanticClassifier
from modules.doc_processor import DocumentProcessor


def add_paper(args):
    """å•ç¯‡è®ºæ–‡å¤„ç†é€»è¾‘ (å°è£…ä¸ºå†…éƒ¨å‡½æ•°ä¾›æ‰¹é‡å¤„ç†è°ƒç”¨)"""
    return _process_single_file(args.path, args.topics)


def _process_single_file(file_path, topics_str, db_manager=None, classifier=None, doc_processor=None):
    """å†…éƒ¨æ ¸å¿ƒé€»è¾‘ï¼šå¤„ç†å•ä»½ PDF æ–‡ä»¶"""
    topics = [t.strip() for t in topics_str.split(",")]

    # å¦‚æœæ²¡ä¼ å…¥åˆ™åˆå§‹åŒ–ï¼ˆæ‰¹é‡å¤„ç†æ—¶å»ºè®®å¤–éƒ¨ä¼ å…¥ä»¥å¤ç”¨æ¨¡å‹åŠ è½½ï¼‰
    doc_processor = doc_processor or DocumentProcessor()
    classifier = classifier or SemanticClassifier()
    db_manager = db_manager or VectorDBManager()

    try:
        print(f"ğŸ”„ æ­£åœ¨å¤„ç†: {os.path.basename(file_path)} ...")
        # è¯»å–å¹¶åˆ‡ç‰‡
        splits, first_page_text = doc_processor.load_and_split(file_path)

        # è¯­ä¹‰åˆ†ç±»
        category = classifier.classify_paper(first_page_text, topics)
        print(f"âœ… å½’ç±»ç»“æœ: [{category}]")

        # ç§»åŠ¨æ–‡ä»¶
        new_path = doc_processor.move_file(file_path, category)

        # æ›´æ–°å…ƒæ•°æ®å¹¶å­˜å…¥å‘é‡åº“
        for split in splits:
            split.metadata['source'] = new_path
            split.metadata['category'] = category

        db_manager.add_documents(splits)
        return True
    except Exception as e:
        print(f"âŒ å¤„ç† {file_path} å‡ºé”™: {e}")
        return False


def batch_process_papers(args):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ PDF"""
    if not os.path.exists(args.dir):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç›®å½• {args.dir}")
        return

    # åˆå§‹åŒ–ç®¡ç†å™¨ï¼ˆåœ¨æ­¤åˆå§‹åŒ–å¯å®ç°æ¨¡å‹å¤ç”¨ï¼Œé¿å…å¾ªç¯åŠ è½½ï¼‰
    doc_processor = DocumentProcessor()
    classifier = SemanticClassifier()
    db_manager = VectorDBManager()

    files = [f for f in os.listdir(args.dir) if f.lower().endswith('.pdf')]
    if not files:
        print(f"â„¹ï¸ åœ¨ç›®å½• {args.dir} ä¸­æœªæ‰¾åˆ° PDF æ–‡ä»¶ã€‚")
        return

    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(files)} ä¸ªæ–‡ä»¶...")
    success_count = 0
    for filename in files:
        full_path = os.path.join(args.dir, filename)
        if _process_single_file(full_path, args.topics, db_manager, classifier, doc_processor):
            success_count += 1

    print(f"\nâœ¨ æ‰¹é‡æ•´ç†å®Œæˆï¼æˆåŠŸå¤„ç†: {success_count}/{len(files)}")


def search_paper(args):
    """è¯­ä¹‰æœç´¢æ–‡çŒ® """
    query = args.query
    db_manager = VectorDBManager()
    k_val = 10 if args.index_only else 3
    print(f"ğŸ” æ­£åœ¨æœç´¢æ–‡çŒ®: '{query}' ...")
    results = db_manager.search_papers(query, k=k_val)

    if not results:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")
        return

    print("\n" + "=" * 60)
    if args.index_only:
        seen_files = set()
        count = 0
        for doc in results:
            source_path = doc.metadata.get('source', 'Unknown')
            if source_path not in seen_files:
                count += 1
                print(f"{count}. ğŸ“„ {os.path.basename(source_path)}\n   è·¯å¾„: {source_path}")
                seen_files.add(source_path)
    else:
        for i, doc in enumerate(results):
            page_num = doc.metadata.get('page', 0) + 1
            print(f"ğŸ” ç»“æœ {i + 1} | ğŸ“„ {os.path.basename(doc.metadata.get('source', ''))}")
            print(f"ğŸ“Œ ä½ç½®: ç¬¬ {page_num} é¡µ | ğŸ·ï¸ ç±»åˆ«: {doc.metadata.get('category', 'Uncategorized')}")
            clean_content = doc.page_content.replace('\n', ' ')
            print(f"ğŸ’¬ ç‰‡æ®µ: \"{clean_content[:250]}...\"")
            print("-" * 60)


def index_images(args):
    """å›¾åƒç´¢å¼• """
    db_manager = VectorDBManager()
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
    if not os.path.exists(args.dir):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç›®å½• {args.dir}")
        return
    img_count = 0
    for root, _, files in os.walk(args.dir):
        for file in files:
            if file.lower().endswith(image_extensions):
                full_path = os.path.join(root, file)
                if db_manager.add_image(full_path):
                    img_count += 1
    print(f"âœ¨ å›¾åƒåº“æ›´æ–°å®Œæ¯•ï¼Œå…±å¤„ç† {img_count} å¼ å›¾ç‰‡ã€‚")


def search_image(args):
    """å›¾åƒæœç´¢ (ä»£ç ä¿æŒä¸å˜)"""
    db_manager = VectorDBManager()
    results = db_manager.search_images(args.query, k=3)
    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…å›¾ç‰‡ã€‚")
        return
    print(f"\nğŸ” é’ˆå¯¹æè¿° '{args.query}' çš„åŒ¹é…ç»“æœ:")
    print("=" * 60)
    for i, res in enumerate(results):
        similarity = max(0, 1 - (res['score'] / 2.0)) * 100
        print(f"ç»“æœ {i + 1} | åŒ¹é…åº¦: {similarity:.2f}% (åŸå§‹è·ç¦»: {res['score']:.4f})")
        print(f"ğŸ“ è·¯å¾„: {res['path']}")
        print("-" * 60)


def main():
    parser = argparse.ArgumentParser(description="Local AI Agent (Multi-modal)")
    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # 1. add_paper (å•æ–‡ä»¶)
    add_p = subparsers.add_parser("add_paper")
    add_p.add_argument("path", type=str)
    add_p.add_argument("--topics", type=str, required=True)

    # 2. batch_process (æ‰¹é‡æ–‡ä»¶å¤¹)
    batch_p = subparsers.add_parser("batch_process")
    batch_p.add_argument("dir", type=str, help="Directory containing multiple PDFs")
    batch_p.add_argument("--topics", type=str, required=True)

    # 3. search_paper
    search_p = subparsers.add_parser("search_paper")
    search_p.add_argument("query", type=str)
    search_p.add_argument("--index-only", action="store_true")

    # 4. index_images
    idx_img_p = subparsers.add_parser("index_images")
    idx_img_p.add_argument("dir", type=str)

    # 5. search_image
    src_img_p = subparsers.add_parser("search_image")
    src_img_p.add_argument("query", type=str)

    args = parser.parse_args()

    if args.command == "add_paper":
        add_paper(args)
    elif args.command == "batch_process":
        batch_process_papers(args)
    elif args.command == "search_paper":
        search_paper(args)
    elif args.command == "index_images":
        index_images(args)
    elif args.command == "search_image":
        search_image(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()